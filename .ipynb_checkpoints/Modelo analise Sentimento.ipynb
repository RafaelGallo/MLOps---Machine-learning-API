{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1599594677390",
   "display_name": "Python 3.7.4 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<bound method Downloader.download of <nltk.downloader.Downloader object at 0x000001EA343F28C8>>"
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download()\n",
    "nltk.download #faz o download das palavras do nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = [('Essa capinha de celular é muito boa', 'alegria'),\n",
    "        ('Gostei muito desta capinha de celular', 'alegria'),\n",
    "        ('Capinha maravilhosa', 'alegria'),\n",
    "        ('Que capinha bonita', 'alegria'),\n",
    "        ('Abaixo do esperado', 'raiva'),\n",
    "        ('Não gostei', 'raiva'),\n",
    "        ('Desbotou na primeira semana', 'raiva'),\n",
    "        ('Olha só essa capinha! ', 'alegria'),\n",
    "        ('Material de baixa resistência', 'raiva'),\n",
    "        ('Custo beneficio excelente', 'alegria'),\n",
    "        ('A foto é diferente do produto', 'raiva')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwordsnltk = nltk.corpus.stopwords.words('portuguese')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[(['ess', 'cap', 'celul', 'boa'], 'alegria'), (['gost', 'dest', 'cap', 'celul'], 'alegria'), (['cap', 'maravilh'], 'alegria'), (['que', 'cap', 'bonit'], 'alegria'), (['abaix', 'esper'], 'raiva'), (['não', 'gost'], 'raiva'), (['desbot', 'prim', 'seman'], 'raiva'), (['olh', 'capinha!'], 'alegria'), (['mater', 'baix', 'resist'], 'raiva'), (['cust', 'benefici', 'excel'], 'alegria'), (['a', 'fot', 'difer', 'produt'], 'raiva')]\n"
    }
   ],
   "source": [
    "def fazstemmer(texto):\n",
    "    \"\"\"\n",
    "    Deixa apenas os radicais das palavras\n",
    "    \"\"\"\n",
    "    stemmer = nltk.stem.RSLPStemmer()\n",
    "    frasessstemming = []\n",
    "    for (palavras, emocao) in texto:\n",
    "        comstemming = [str(stemmer.stem(p))\n",
    "                       for p in palavras.split() if p not in stopwordsnltk]\n",
    "        frasessstemming.append((comstemming, emocao))\n",
    "    return frasessstemming\n",
    "\n",
    "\n",
    "frasescomstemming = fazstemmer(base)\n",
    "print(frasescomstemming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "['ess', 'cap', 'celul', 'boa', 'gost', 'dest', 'cap', 'celul', 'cap', 'maravilh', 'que', 'cap', 'bonit', 'abaix', 'esper', 'não', 'gost', 'desbot', 'prim', 'seman', 'olh', 'capinha!', 'mater', 'baix', 'resist', 'cust', 'benefici', 'excel', 'a', 'fot', 'difer', 'produt']\n"
    }
   ],
   "source": [
    "def buscapalavras(frases):\n",
    "    \"\"\"\n",
    "    Busca as palavras nas frases e separa das emoções\n",
    "    \"\"\"\n",
    "    todaspalavras = []\n",
    "    for (palavras, emocao) in frases:\n",
    "        todaspalavras.extend(palavras)\n",
    "    return todaspalavras\n",
    "\n",
    "\n",
    "palavras = buscapalavras(frasescomstemming)\n",
    "print(palavras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buscafrequencia(palavras):\n",
    "    \"\"\"\n",
    "    Define a frequência que as palavras aparecem no banco de dados\n",
    "    \"\"\"\n",
    "    palavras = nltk.FreqDist(palavras)\n",
    "    return palavras\n",
    "\n",
    "\n",
    "frequenciatreinamento = buscafrequencia(palavras)\n",
    "#print(frequencia.most_common(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "dict_keys(['ess', 'cap', 'celul', 'boa', 'gost', 'dest', 'maravilh', 'que', 'bonit', 'abaix', 'esper', 'não', 'desbot', 'prim', 'seman', 'olh', 'capinha!', 'mater', 'baix', 'resist', 'cust', 'benefici', 'excel', 'a', 'fot', 'difer', 'produt'])\ndict_keys(['ess', 'cap', 'celul', 'boa', 'gost', 'dest', 'maravilh', 'que', 'bonit', 'abaix', 'esper', 'não', 'desbot', 'prim', 'seman', 'olh', 'capinha!', 'mater', 'baix', 'resist', 'cust', 'benefici', 'excel', 'a', 'fot', 'difer', 'produt'])\n"
    }
   ],
   "source": [
    "def busca_palavrasunicas(frequencia):\n",
    "    \"\"\"\n",
    "    Cria um dicionário de palavras únicas\n",
    "    \"\"\"\n",
    "    freq = frequencia.keys()\n",
    "    return freq\n",
    "\n",
    "\n",
    "palavrasunicas = busca_palavrasunicas(frequenciatreinamento)\n",
    "print(palavrasunicas)\n",
    "print(palavrasunicas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "{'ess': False, 'cap': False, 'celul': False, 'boa': False, 'gost': False, 'dest': False, 'maravilh': False, 'que': False, 'bonit': False, 'abaix': False, 'esper': False, 'não': False, 'desbot': False, 'prim': False, 'seman': False, 'olh': False, 'capinha!': False, 'mater': False, 'baix': False, 'resist': False, 'cust': False, 'benefici': False, 'excel': False, 'a': False, 'fot': False, 'difer': False, 'produt': False}\n['alegria', 'raiva']\nMost Informative Features\n                     cap = False           raiva : alegri =      2.6 : 1.0\n                   celul = False           raiva : alegri =      1.4 : 1.0\n                   abaix = False          alegri : raiva  =      1.2 : 1.0\n                  resist = False          alegri : raiva  =      1.2 : 1.0\n                    prim = False          alegri : raiva  =      1.2 : 1.0\nNone\n"
    }
   ],
   "source": [
    "def extraipalavras(documento):\n",
    "    doc = set(documento)\n",
    "    caracteristicas = {}\n",
    "    for palavras in palavrasunicas:\n",
    "        caracteristicas['%s' % palavras] = (palavras in doc)\n",
    "    return caracteristicas\n",
    "\n",
    "\n",
    "caracteristicasfrase = extraipalavras(['am', 'nov', 'dia'])\n",
    "print(caracteristicasfrase)\n",
    "\n",
    "basecompleta = nltk.classify.apply_features(extraipalavras, frasescomstemming)\n",
    "#print(basecompleta[15])\n",
    "\n",
    "# constroi a tabela de probabilidade\n",
    "classificador = nltk.NaiveBayesClassifier.train(basecompleta)\n",
    "print(classificador.labels())\n",
    "print(classificador.show_most_informative_features(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'extrai_palavras' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-3c1086c8d5c2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mnova_frase\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextrai_palavras\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestestem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mdistribuicao\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclassificador\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprob_classify\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnova_frase\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'extrai_palavras' is not defined"
     ]
    }
   ],
   "source": [
    "teste = 'Eu nunca mais compro campinha de celular desta marca'\n",
    "testestem = []\n",
    "stemmer = nltk.stem.RSLPStemmer()\n",
    "for (palavrastreinamento) in teste.split():\n",
    "    comstem = [p for p in palavrastreinamento.split()]\n",
    "    testestem.append(str(stemmer.stem(comstem[0])))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "nova_frase = extrai_palavras(testestem)\n",
    "\n",
    "distribuicao = classificador.prob_classify(nova_frase)\n",
    "print('-----------------------')\n",
    "for classe in distribuicao.samples():\n",
    "    print(\"%s: %f\" % (classe, distribuicao.prob(classe)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}